{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import django\n",
    "import pytz\n",
    "from dateutil import parser\n",
    "TIME_ZONE = 'Africa/Gaborone'\n",
    "tz = pytz.timezone(TIME_ZONE)\n",
    "\n",
    "sys.path.append('../..') # add path to project root dir\n",
    "os.environ[\"DJANGO_SETTINGS_MODULE\"] = \"cancer.settings\"\n",
    "\n",
    "# for more sophisticated setups, if you need to change connection settings (e.g. when using django-environ):\n",
    "#os.environ[\"DATABASE_URL\"] = \"postgres://myuser:mypassword@localhost:54324/mydb\"\n",
    "\n",
    "# Connect to Django ORM\n",
    "django.setup()\n",
    "import uuid\n",
    "from django.contrib.sites.models import Site\n",
    "from django.core.exceptions import ValidationError\n",
    "sites = {'gaborone': '31ca7098-02f6-11e2-b134-00188b4d6b0e',\n",
    "        'francistown': 'b98d0c3a-d97b-4999-bc8f-961bfb5476f1'}\n",
    "try:\n",
    "    gaborone = Site.objects.get(id='040')\n",
    "except Site.DoesNotExist:\n",
    "    gaborone = Site.objects.create(id='040', domain='gaborone.cancer.bhp.org.bw', name='gaborone.cancer.bhp.org.bw')\n",
    "try:\n",
    "    francistown = Site.objects.get(id='060')\n",
    "except Site.DoesNotExist:\n",
    "    francistown = Site.objects.create(id='060', name='francistown.cancer.bhp.org.bw', domain='francistown.cancer.bhp.org.bw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "045-40990021-9 ############\n",
      "045-40990020-1 ############\n",
      "045-40990019-3 ############\n",
      "045-40990018-5 ############\n",
      "045-40990017-7 ############\n",
      "045-40990016-9 ############\n",
      "045-40990015-1 ############\n",
      "045-40990014-4 ############\n",
      "045-40990013-6 ############\n",
      "045-60990003-5 ############\n",
      "045-40990012-8 ############\n",
      "045-40990011-0 ############\n",
      "045-40990010-2 ############\n",
      "045-40990009-4 ############\n",
      "045-40990008-6 ############\n",
      "045-40990007-8 ############\n",
      "045-40990006-0 ############\n",
      "045-40990005-2 ############\n",
      "045-40990004-5 ############\n",
      "045-60990002-7 ############\n",
      "045-60990001-9 ############\n",
      "045-40990003-7 ############\n",
      "045-40990002-9 ############\n",
      "045-40990001-1 ############\n",
      "Total created consents 24\n",
      "Already created 12\n"
     ]
    }
   ],
   "source": [
    "# Subject Consent\n",
    "import uuid\n",
    "from cancer_subject.models import SubjectConsent\n",
    "from django.contrib.sites.models import Site\n",
    "from django.core.exceptions import ValidationError\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/subject_consent.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "del headers[0]\n",
    "lines.pop(0)\n",
    "\n",
    "s_consent_data = []\n",
    "count = 0\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(headers)\n",
    "        print('---------------------------------')\n",
    "        print(line)\n",
    "        print(len(line))\n",
    "        print(len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    s_consent_data.append(data)\n",
    "    count += 0\n",
    "gaborone = Site.objects.get(id=40)\n",
    "francistown = Site.objects.get(id=60)\n",
    "\n",
    "count = 0\n",
    "already_created = 0\n",
    "for dd in s_consent_data:\n",
    "    del dd['_state']\n",
    "    created = parser.parse(dd.get('created'))\n",
    "    created = created.replace(tzinfo=tz)\n",
    "    consent_datetime = parser.parse(dd.get('consent_datetime'))\n",
    "    consent_datetime = consent_datetime.replace(tzinfo=tz)\n",
    "    dob = parser.parse(dd.get('dob')).replace(tzinfo=tz)\n",
    "    dob = dob.date()\n",
    "    dd.update(\n",
    "        created=created,\n",
    "        consent_datetime=consent_datetime,\n",
    "        report_datetime=parser.parse(dd.get('report_datetime')).replace(tzinfo=tz),\n",
    "        dob=dob,\n",
    "        id=uuid.UUID(dd.get('id'))\n",
    "    )\n",
    "    if dd['subject_identifier_as_pk']:\n",
    "        dd.update(\n",
    "            subject_identifier_as_pk=uuid.UUID(dd.get('subject_identifier_as_pk')))\n",
    "    else:\n",
    "        dd.update(\n",
    "            subject_identifier_as_pk=dd.get('id'))\n",
    "    if dd['is_verified_datetime']:\n",
    "        is_verified_datetime = parser.parse(dd.get('is_verified_datetime'))\n",
    "        is_verified_datetime = is_verified_datetime.replace(tzinfo=tz)\n",
    "        dd.update(\n",
    "        is_verified_datetime=is_verified_datetime)\n",
    "    else:\n",
    "        dd.update(is_verified_datetime=None)\n",
    "    if dd['modified']:\n",
    "        modified = parser.parse(dd.get('modified'))\n",
    "        modified = modified.replace(tzinfo=tz)\n",
    "        dd.update(modified=modified)\n",
    "    else:\n",
    "        dd.update(modified=None)\n",
    "    if dd['is_verified'] == 'TRUE':\n",
    "        dd.update(is_verified=True)\n",
    "    elif dd['is_verified'] == 'FALSE':\n",
    "        dd.update(is_verified=False)\n",
    "    if dd['guardian_name']:\n",
    "        guardian_name = dd['guardian_name']\n",
    "        name1, name2 = guardian_name.split(',')\n",
    "        guardian_name = name1 + ', ' + name2\n",
    "        dd.update(guardian_name=guardian_name)\n",
    "    if dd['slug']:\n",
    "        slug = dd['slug']\n",
    "        slug = slug.split(' ')\n",
    "        slug = slug[0] + '|' + slug[1] + '|' + slug[2]\n",
    "        dd.update(slug=slug)\n",
    "    try:\n",
    "        SubjectConsent.objects.get(subject_identifier=dd.get('subject_identifier'))\n",
    "    except SubjectConsent.DoesNotExist:\n",
    "        print(dd.get('subject_identifier'), '############')\n",
    "        subject_consent = SubjectConsent(**dd)\n",
    "        subject_consent.save_base(raw=True)\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created consents {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total created registered subjects 24\n",
      "Already created 1\n"
     ]
    }
   ],
   "source": [
    "# Registered Subject\n",
    "from edc_registration.models import RegisteredSubject\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/registered_subject.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "\n",
    "rs_data = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(headers)\n",
    "        print(line)\n",
    "        print(len(line))\n",
    "        print(len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    rs_data.append(data)\n",
    "\n",
    "gaborone = Site.objects.get(id=40)\n",
    "francistown = Site.objects.get(id=60)\n",
    "already_created = 0\n",
    "count = 0\n",
    "for rs in rs_data:\n",
    "    del rs['_state']\n",
    "    rs.update(\n",
    "        created=parser.parse(rs.get('created')).replace(tzinfo=tz),\n",
    "        dob=parser.parse(rs.get('dob')).replace(tzinfo=tz).date(),\n",
    "        id=uuid.UUID(rs.get('id'))\n",
    "    )\n",
    "    if rs['modified']:\n",
    "        rs.update(modified=parser.parse(rs.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        rs.update(modified=None)\n",
    "    if rs['screening_datetime']:\n",
    "        rs.update(\n",
    "            screening_datetime=parser.parse(rs.get('screening_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        rs.update(screening_datetime=None)\n",
    "    if rs['registration_datetime']:\n",
    "        rs.update(\n",
    "            registration_datetime=parser.parse(rs.get('registration_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        rs.update(registration_datetime=None)\n",
    "    if rs['randomization_datetime']:\n",
    "        rs.update(\n",
    "            randomization_datetime=parser.parse(rs.get('randomization_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        rs.update(randomization_datetime=None)\n",
    "    try:\n",
    "            subject_consent = SubjectConsent.objects.get(subject_identifier=rs.get('subject_identifier'))\n",
    "    except SubjectConsent.DoesNotExist:\n",
    "        print(rs.get('subject_identifier'))\n",
    "        raise ValidationError('This guy can not be missing a consent')\n",
    "    if rs['subject_identifier_as_pk']:\n",
    "        rs.update(\n",
    "            subject_identifier_as_pk=uuid.UUID(rs.get('subject_identifier_as_pk')))\n",
    "    else:\n",
    "         rs.update(\n",
    "            subject_identifier_as_pk=subject_consent.subject_identifier_as_pk)\n",
    "    if rs['screening_age_in_years']:\n",
    "        rs.update(screening_age_in_years=int(rs['screening_age_in_years']))\n",
    "    else:\n",
    "        rs.update(screening_age_in_years=None)\n",
    "    try:\n",
    "        RegisteredSubject.objects.get(subject_identifier=rs.get('subject_identifier'))\n",
    "    except RegisteredSubject.DoesNotExist:\n",
    "        registered_subject = RegisteredSubject(**rs)\n",
    "        registered_subject.save_base(raw=True)\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created registered subjects {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total created subject screening 24\n",
      "Already created 1\n"
     ]
    }
   ],
   "source": [
    "# Subject Screening\n",
    "from cancer_subject.models import SubjectScreening\n",
    "from cancer_subject.screening_identifier import ScreeningIdentifier\n",
    "from django.contrib.sites.models import Site\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/subject_screening.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "\n",
    "sc_data = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(headers)\n",
    "        print(line)\n",
    "        print(len(line))\n",
    "        print(len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    sc_data.append(data)\n",
    "\n",
    "count = 0\n",
    "already_created = 0\n",
    "for sc in sc_data:\n",
    "    del sc['_state']\n",
    "    sc.update(\n",
    "        report_datetime=parser.parse(sc.get('report_datetime')).replace(tzinfo=tz),\n",
    "        created=parser.parse(sc.get('created')).replace(tzinfo=tz),\n",
    "        screening_identifier=ScreeningIdentifier().identifier,\n",
    "        id=uuid.UUID(sc.get('id'))\n",
    "    )\n",
    "    if sc['modified']:\n",
    "        sc.update(modified=parser.parse(sc.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        sc.update(modified=None)\n",
    "    try:\n",
    "        SubjectScreening.objects.get(id=sc.get('id'))\n",
    "    except SubjectScreening.DoesNotExist:\n",
    "        subject_Screening = SubjectScreening(**sc)\n",
    "        subject_Screening.save_base(raw=True)\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created subject screening {count}')\n",
    "print(f'Already created {already_created}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526 Total number of apps\n",
      "Total created subject appointment 525\n",
      "Already created 1\n"
     ]
    }
   ],
   "source": [
    "# Import appointments\n",
    "from cancer_subject.models import Appointment\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/appointment.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "\n",
    "ap_data = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(headers)\n",
    "        print(line)\n",
    "        print(len(line))\n",
    "        print(len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    data = dict(zip(headers, line))\n",
    "    ap_data.append(data)\n",
    "\n",
    "count = 0\n",
    "already_created = 0\n",
    "print(len(ap_data), 'Total number of apps')\n",
    "for ap in ap_data:\n",
    "    del ap['_state']\n",
    "    ap.update(\n",
    "        created=parser.parse(ap.get('created')).replace(tzinfo=tz),\n",
    "        id=uuid.UUID(ap.get('id')),\n",
    "    )\n",
    "    if ap['appt_close_datetime']:\n",
    "        ap.update(\n",
    "            appt_close_datetime=parser.parse(ap.get('appt_close_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        ap.update(appt_close_datetime=None)\n",
    "    if ap['timepoint_datetime']:\n",
    "        ap.update(\n",
    "            timepoint_datetime=parser.parse(ap.get('timepoint_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        ap.update(timepoint_datetime=None)\n",
    "    if ap['modified']:\n",
    "        ap.update(modified=parser.parse(ap.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        ap.update(modified=None)\n",
    "    if ap['timepoint_closed_datetime']:\n",
    "        ap.update(timepoint_closed_datetime=parser.parse(ap.get('timepoint_closed_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        ap.update(timepoint_closed_datetime=None)\n",
    "    if ap['appt_datetime']:\n",
    "        ap.update(\n",
    "        appt_datetime=parser.parse(ap.get('appt_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        ap.update(appt_datetime=None)\n",
    "    if ap['is_confirmed'] == 'FALSE':\n",
    "        ap.update(is_confirmed=False)\n",
    "    elif ap['is_confirmed'] == 'TRUE':\n",
    "        ap.update(is_confirmed=True)\n",
    "    if ap['timepoint']:\n",
    "        ap.update(timepoint=float(ap['timepoint']))\n",
    "    else:\n",
    "        ap.update(timepoint=None)\n",
    "    try:\n",
    "        Appointment.objects.get(id=ap.get('id'))\n",
    "    except Appointment.DoesNotExist:\n",
    "        appointment = Appointment(**ap)\n",
    "        appointment.save_base(raw=True)\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1  \n",
    "print(f'Total created subject appointment {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total created subject visits 24\n",
      "Already created 58\n"
     ]
    }
   ],
   "source": [
    "# Subject visit\n",
    "from datetime import timedelta\n",
    "from cancer_subject.models import SubjectVisit, Appointment\n",
    "from django.db.utils import IntegrityError\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/subject_visit.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "\n",
    "\n",
    "sv_data = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(headers)\n",
    "        print(line)\n",
    "        print(len(line))\n",
    "        print(len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    data = dict(zip(headers, line))\n",
    "    sv_data.append(data)\n",
    "\n",
    "count = 0\n",
    "already_created = 0\n",
    "for sv in sv_data:\n",
    "    del sv['_state']\n",
    "    sv.update(\n",
    "        created=parser.parse(sv.get('created')).replace(tzinfo=tz),\n",
    "        id=uuid.UUID(sv.get('id')),\n",
    "    )\n",
    "    if sv['last_alive_date']:\n",
    "        sv.update(\n",
    "            last_alive_date=parser.parse(sv.get('last_alive_date')).replace(tzinfo=tz).date())\n",
    "    else:\n",
    "        sv.update(last_alive_date=None)\n",
    "    \n",
    "    if sv['report_datetime']:\n",
    "        sv.update(\n",
    "            report_datetime=parser.parse(sv.get('report_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        sv.update(report_datetime=None)\n",
    "    if sv['modified']:\n",
    "        sv.update(\n",
    "            modified=parser.parse(sv.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        sv.update(modified=None)\n",
    "    try:\n",
    "        appointment = Appointment.objects.get(id=uuid.UUID(sv.get('appointment_id')))\n",
    "    except Appointment.DoesNotExist:\n",
    "        print(sv.get('appointment_id'))\n",
    "        count_missing += 1\n",
    "    else:\n",
    "        appointment = Appointment.objects.get(id=sv.get('appointment_id'))\n",
    "        sv.update(appointment=appointment)\n",
    "    try:\n",
    "        SubjectVisit.objects.get(id=sv.get('id'))\n",
    "    except SubjectVisit.DoesNotExist:\n",
    "        subject_visit = SubjectVisit(**sv)\n",
    "        subject_visit.save_base(raw=True)\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created subject visits {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Created: 23 for symptomsandtesting\n",
      "Already Exists: 2 for symptomsandtesting\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 20 for labresultheightweight\n",
      "Already Exists: 1 for labresultheightweight\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for activityandfunctioning\n",
      "Already Exists: 54 for activityandfunctioning\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for baseriskassessmentdemo\n",
      "Already Exists: 2 for baseriskassessmentdemo\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for baseriskassessment\n",
      "Already Exists: 2 for baseriskassessment\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 21 for baseriskassessmentfemale\n",
      "Already Exists: 2 for baseriskassessmentfemale\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for baseriskassessmentcancer\n",
      "Already Exists: 2 for baseriskassessmentcancer\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for baseriskassessmentsun\n",
      "Already Exists: 2 for baseriskassessmentsun\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for baseriskassessmentfuel\n",
      "Already Exists: 2 for baseriskassessmentfuel\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for baseriskassessmentchemical\n",
      "Already Exists: 1 for baseriskassessmentchemical\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 1 for baseriskassessmentmining\n",
      "Already Exists: 0 for baseriskassessmentmining\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 24 for baseriskassessmenteating\n",
      "Already Exists: 2 for baseriskassessmenteating\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 5 for baseriskassessmentsmoking\n",
      "Already Exists: 0 for baseriskassessmentsmoking\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 2 for baseriskassessmentalcohol\n",
      "Already Exists: 0 for baseriskassessmentalcohol\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 9 for cancerdiagnosis\n",
      "Already Exists: 2 for cancerdiagnosis\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 3 for oncologytreatmentplan\n",
      "Already Exists: 4 for oncologytreatmentplan\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for labresulthaematology\n",
      "Already Exists: 0 for labresulthaematology\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for labresultchemistry\n",
      "Already Exists: 0 for labresultchemistry\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for labresulttb\n",
      "Already Exists: 0 for labresulttb\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 6 for baselinehivhistory\n",
      "Already Exists: 0 for baselinehivhistory\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 6 for bhhhivtest\n",
      "Already Exists: 1 for bhhhivtest\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for bhhwhoillness\n",
      "Already Exists: 0 for bhhwhoillness\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for haartrecord\n",
      "Already Exists: 0 for haartrecord\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 8 for oncologytreatmentrecord\n",
      "Already Exists: 1 for oncologytreatmentrecord\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for otrsurgical\n",
      "Already Exists: 1 for otrsurgical\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for otrchemo\n",
      "Already Exists: 0 for otrchemo\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for radiationtreatment\n",
      "Already Exists: 3 for radiationtreatment\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for currentsymptoms\n",
      "Already Exists: 52 for currentsymptoms\n",
      "###################################################\n",
      "**************************************************\n",
      "Created: 0 for oncologytreatmentcompleted\n",
      "Already Exists: 1 for oncologytreatmentcompleted\n",
      "###################################################\n",
      "Done with all CRFS\n"
     ]
    }
   ],
   "source": [
    "# Import CRFs\n",
    "import csv\n",
    "from decimal import Decimal\n",
    "from django.apps import apps as django_apps\n",
    "from cancer_subject.models import SubjectVisit\n",
    "from django.core.handlers import exception\n",
    "from django.db.utils import DataError\n",
    "from django.db.utils import IntegrityError\n",
    "from builtins import ValueError\n",
    "crf_list = [\n",
    "    'symptomsandtesting', 'labresultheightweight', 'activityandfunctioning', 'baseriskassessmentdemo', 'baseriskassessment',\n",
    "    'baseriskassessmentfemale', 'baseriskassessmentcancer', 'baseriskassessmentsun', 'baseriskassessmentfuel',\n",
    "    'baseriskassessmentchemical', 'baseriskassessmentmining', 'baseriskassessmenteating', 'baseriskassessmentsmoking',\n",
    "    'baseriskassessmentalcohol', 'cancerdiagnosis', 'oncologytreatmentplan', 'labresulthaematology', 'labresultchemistry',\n",
    "    'labresulttb', 'baselinehivhistory', 'bhhhivtest', 'bhhwhoillness', 'haartrecord', 'oncologytreatmentrecord',\n",
    "    'otrsurgical', 'otrchemo', 'radiationtreatment', 'currentsymptoms', 'oncologytreatmentcompleted']\n",
    "data_path = '/Users/coulsonkgathi/source/data_files/live_s_d/crfs/'\n",
    "missing_facility = []\n",
    "for crf_name in crf_list:\n",
    "    fname = data_path + crf_name + '.csv'\n",
    "    with open(fname, encoding=\"ISO-8859-1\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter='|')\n",
    "        header = next(csv_reader)\n",
    "        del header[0]\n",
    "        created = 0\n",
    "        already_exists = 0\n",
    "        count = 0\n",
    "        for line in csv_reader:\n",
    "            del line[0]\n",
    "            if len(line) == len(header):\n",
    "                data = dict(zip(header, line))\n",
    "            else:\n",
    "                print(lines[count - 1])\n",
    "                print(line)\n",
    "                print(lines[count + 1])\n",
    "                raise ValidationError('Line is not the right size')\n",
    "            data.update(\n",
    "            created=parser.parse(data.get('created')).replace(tzinfo=tz),\n",
    "            id=uuid.UUID(data.get('id')))\n",
    "            if data['modified']:\n",
    "                data.update(\n",
    "                    modified=parser.parse(data.get('modified')).replace(tzinfo=tz))\n",
    "            else:\n",
    "                data.update(modified=None)\n",
    "            if data['report_datetime']:\n",
    "                data.update(\n",
    "                    report_datetime=parser.parse(data.get('report_datetime')).replace(tzinfo=tz))\n",
    "            else:\n",
    "                data.update(report_datetime=None)\n",
    "            if 'labresultheightweight' == crf_name:\n",
    "                if data['weight']:\n",
    "                    data.update(weight=float(data.get('weight')))\n",
    "                else:\n",
    "                    data.update(weight=None)\n",
    "                if data['height']:\n",
    "                    data.update(height=float(data.get('height')))\n",
    "                else:\n",
    "                    data.update(height=None)\n",
    "            if 'symptomsandtesting' == crf_name:\n",
    "                if data['art_art_stop_date']:\n",
    "                    data.update(\n",
    "                        art_art_stop_date=parser.parse(data.get('art_art_stop_date')).replace(tzinfo=tz))\n",
    "                else:\n",
    "                    data.update(art_art_stop_date=None)\n",
    "                if data['arv_art_start_date']:\n",
    "                    data.update(\n",
    "                        arv_art_start_date=parser.parse(data.get('arv_art_start_date')).replace(tzinfo=tz))\n",
    "                else:\n",
    "                    data.update(arv_art_start_date=None)\n",
    "                if data['symptom_date']:\n",
    "                    data.update(\n",
    "                        symptom_date=parser.parse(data.get('symptom_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(symptom_date=None)\n",
    "                if data['neg_date']:\n",
    "                    data.update(\n",
    "                        neg_date=parser.parse(data.get('neg_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(neg_date=None)\n",
    "                if data['pos_date']:\n",
    "                    data.update(\n",
    "                        pos_date=parser.parse(data.get('pos_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(pos_date=None)\n",
    "                if data['medical_doctor_date']:\n",
    "                    data.update(\n",
    "                        medical_doctor_date=parser.parse(data.get('medical_doctor_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(medical_doctor_date=None)\n",
    "                if data['trad_doctor_date']:\n",
    "                    data.update(\n",
    "                        trad_doctor_date=parser.parse(data.get('trad_doctor_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(trad_doctor_date=None)\n",
    "                if not data['facility_first_seen']:\n",
    "                    data.update(facility_first_seen='00-0-00')\n",
    "                    try:\n",
    "                        subject_visit = SubjectVisit.objects.get(id=data.get('subject_visit_id'))\n",
    "                    except SubjectVisit.DoesNotExist:\n",
    "                        raise ValidationError('Missing visit')\n",
    "                    else:\n",
    "                        missing_facility.append([subject_visit.subject_identifier, subject_visit.visit_code])\n",
    "            if 'baseriskassessment' == crf_name:\n",
    "                if data['year_tb']:\n",
    "                    if len(data['year_tb']) == 10:\n",
    "                        year_tb = data['year_tb'][:4]\n",
    "                        data.update(\n",
    "                            year_tb=int(float(year_tb)))\n",
    "                    else:\n",
    "                        data.update(\n",
    "                            year_tb=int(float(data.get('year_tb'))))\n",
    "                else:\n",
    "                    data.update(year_tb=None)\n",
    "            if 'baseriskassessmentmining' == crf_name:\n",
    "                if data['last_mine']:\n",
    "                    data.update(\n",
    "                        last_mine=parser.parse(data.get('last_mine')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(last_mine=None)\n",
    "            if 'baseriskassessmentsmoking' == crf_name:\n",
    "                if data['years_smoked']:\n",
    "                    data.update(years_smoked=int(float(data.get('years_smoked'))))\n",
    "                else:\n",
    "                    data.update(years_smoked=None)\n",
    "                if data['years_smoked_before']:\n",
    "                    data.update(years_smoked_before=int(float(data.get('years_smoked_before'))))\n",
    "                else:\n",
    "                    data.update(years_smoked_before=None)\n",
    "            if 'cancerdiagnosis' == crf_name:\n",
    "                if data['symptom_first_noticed']:\n",
    "                    data.update(\n",
    "                        symptom_first_noticed=parser.parse(data.get('symptom_first_noticed')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(symptom_first_noticed=None)\n",
    "                if data['date_diagnosed']:\n",
    "                    data.update(\n",
    "                        date_diagnosed=parser.parse(data.get('date_diagnosed')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(date_diagnosed=None)\n",
    "                if data['first_evaluation']:\n",
    "                    data.update(\n",
    "                        first_evaluation=parser.parse(data.get('first_evaluation')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(first_evaluation=None)\n",
    "                if data['trad_evaluation']:\n",
    "                    data.update(\n",
    "                        trad_evaluation=parser.parse(data.get('trad_evaluation')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(trad_evaluation=None)\n",
    "            if 'labresulthaematology' == crf_name:\n",
    "                if data['haem_drawn_date']:\n",
    "                    data.update(\n",
    "                        haem_drawn_date=parser.parse(data.get('haem_drawn_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(haem_drawn_date=None)\n",
    "                if data['hgb']:\n",
    "                    data.update(hgb=float(data.get('hgb')))\n",
    "                else:\n",
    "                    data.update(hgb=None)\n",
    "                if data['mcv']:\n",
    "                    data.update(mcv=float(data.get('mcv')))\n",
    "                else:\n",
    "                    data.update(mcv=None)\n",
    "                if data['wbc_count']:\n",
    "                    data.update(wbc_count=float(data.get('wbc_count')))\n",
    "                else:\n",
    "                    data.update(wbc_count=None)\n",
    "                if data['anc_count']:\n",
    "                    data.update(anc_count=float(data.get('anc_count')))\n",
    "                else:\n",
    "                    data.update(anc_count=None)\n",
    "                if data['platelet']:\n",
    "                    data.update(platelet=float(data.get('platelet')))\n",
    "                else:\n",
    "                    data.update(platelet=None)\n",
    "            if 'labresultchemistry' == crf_name:\n",
    "                if data['chem_drawn_date']:\n",
    "                    data.update(\n",
    "                        chem_drawn_date=parser.parse(data.get('chem_drawn_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(chem_drawn_date=None)\n",
    "                if data['alanine']:\n",
    "                    data.update(alanine=float(data.get('alanine')))\n",
    "                else:\n",
    "                    data.update(alanine=None)\n",
    "                if data['aspartate']:\n",
    "                    data.update(aspartate=float(data.get('aspartate')))\n",
    "                else:\n",
    "                    data.update(aspartate=None)\n",
    "                if data['bilirubin']:\n",
    "                    data.update(bilirubin=float(data.get('bilirubin')))\n",
    "                else:\n",
    "                    data.update(bilirubin=None)\n",
    "                if data['creatinine']:\n",
    "                    data.update(creatinine=float(data.get('creatinine')))\n",
    "                else:\n",
    "                    data.update(creatinine=None)\n",
    "                if data['lactate']:\n",
    "                    data.update(lactate=float(data.get('lactate')))\n",
    "                else:\n",
    "                    data.update(lactate=None)\n",
    "            if 'labresulttb' == crf_name:\n",
    "                if data['tb_treatment_start']:\n",
    "                    data.update(\n",
    "                        tb_treatment_start=parser.parse(data.get('tb_treatment_start')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(tb_treatment_start=None)\n",
    "            if 'baselinehivhistory' == crf_name:\n",
    "                if data['cd4_result']:\n",
    "                    data.update(cd4_result=float(data.get('cd4_result')))\n",
    "                else:\n",
    "                    data.update(cd4_result=None)\n",
    "                if data['nadir_cd4']:\n",
    "                    data.update(nadir_cd4=float(data.get('nadir_cd4')))\n",
    "                else:\n",
    "                    data.update(nadir_cd4=None)\n",
    "                if data['cd4_drawn_date']:\n",
    "                    data.update(\n",
    "                        cd4_drawn_date=parser.parse(data.get('cd4_drawn_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(cd4_drawn_date=None)\n",
    "                if data['nadir_cd4_drawn_date']:\n",
    "                    data.update(\n",
    "                        nadir_cd4_drawn_date=parser.parse(data.get('nadir_cd4_drawn_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(nadir_cd4_drawn_date=None)\n",
    "                if data['vl_drawn_date']:\n",
    "                    data.update(\n",
    "                        vl_drawn_date=parser.parse(data.get('vl_drawn_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(vl_drawn_date=None)\n",
    "            if 'bhhhivtest' == crf_name:\n",
    "                if data['hiv_drawn_date']:\n",
    "                    data.update(\n",
    "                        hiv_drawn_date=parser.parse(data.get('hiv_drawn_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(hiv_drawn_date=None)\n",
    "            if 'bhhwhoillness' == crf_name:\n",
    "                if data['who_illness_date']:\n",
    "                    data.update(\n",
    "                        who_illness_date=parser.parse(data.get('who_illness_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(who_illness_date=None)\n",
    "            if 'otrsurgical' == crf_name:\n",
    "                if data['date_operation']:\n",
    "                    data.update(\n",
    "                        date_operation=parser.parse(data.get('date_operation')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(date_operation=None)\n",
    "            if 'radiationtreatment' == crf_name:\n",
    "                if data['treatment_start_date']:\n",
    "                    data.update(\n",
    "                        treatment_start_date=parser.parse(data.get('treatment_start_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(treatment_start_date=None)\n",
    "                if data['treatment_end_date']:\n",
    "                    data.update(\n",
    "                        treatment_end_date=parser.parse(data.get('treatment_end_date')).replace(tzinfo=tz).date())\n",
    "                else:\n",
    "                    data.update(treatment_end_date=None)\n",
    "            del data['_state']\n",
    "            crf_cls = django_apps.get_model('cancer_subject', crf_name)\n",
    "            if 'labresultheightweight' == crf_name:\n",
    "                if not data['weight']:\n",
    "                    data.update(weight=0)\n",
    "                if not data['height']:\n",
    "                    data.update(height=0)\n",
    "            if data['site_id']:\n",
    "                data.update(site_id=int(float(data['site_id'])))\n",
    "            try:\n",
    "                crf_cls.objects.get(id=data.get('id'))\n",
    "            except crf_cls.DoesNotExist:\n",
    "                obj = crf_cls(**data)\n",
    "                obj.save_base(raw=True)\n",
    "                created += 1\n",
    "            else:\n",
    "                already_exists += 1\n",
    "        print('**************************************************')\n",
    "        print(f'Created: {created} for {crf_name}')\n",
    "        print(f'Already Exists: {already_exists} for {crf_name}')\n",
    "        print('###################################################')\n",
    "print('Done with all CRFS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/coulsonkgathi/source/data_files/live_s_d/locator_action_items.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0b4793e50699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/coulsonkgathi/source/data_files/live_s_d/locator_action_items.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/coulsonkgathi/source/data_files/live_s_d/locator_action_items.csv'"
     ]
    }
   ],
   "source": [
    "# Import locator action items\n",
    "from cancer_subject.models import SubjectLocator, SubjectConsent\n",
    "from edc_action_item.models import ActionItem, ActionType\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/locator_action_items.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "\n",
    "sl_data = []\n",
    "count = 0\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(line)\n",
    "        print('line: ', len(line))\n",
    "        print('headers: ', len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    data = dict(zip(headers, line))\n",
    "    sl_data.append(data)\n",
    "    count += 1\n",
    "\n",
    "count = 0\n",
    "for ai in sl_data:\n",
    "    del ai['_state']\n",
    "    ai.update(\n",
    "        created=parser.parse(ai.get('created')).replace(tzinfo=tz),\n",
    "        id=uuid.UUID(ai.get('id'))\n",
    "    )\n",
    "    if ai['modified']:\n",
    "        ai.update(modified=parser.parse(ai.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        ai.update(modified=None)\n",
    "    if ai['report_datetime']:\n",
    "        ai.update(report_datetime=parser.parse(ai.get('report_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        ai.update(report_datetime=None)\n",
    "    action_type = ActionType.objects.get(id='e61bc0cf-7907-44da-b704-f42067cf3f2a')\n",
    "    ai.update(action_type=action_type)\n",
    "    try:\n",
    "        ActionItem.objects.get(subject_identifier=ai.get('action_identifier'))\n",
    "    except ActionItem.DoesNotExist:\n",
    "        locator_action_item = ActionItem(**ai)\n",
    "        locator_action_item.save_base(raw=True)\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created subject locator {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total created subject locator 20\n",
      "Already created 2\n"
     ]
    }
   ],
   "source": [
    "# Import Locators\n",
    "from cancer_subject.models import SubjectLocator, SubjectConsent\n",
    "from edc_action_item.models import ActionItem\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/crfs/subject_locator.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "\n",
    "sl_data = []\n",
    "count = 0\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(line)\n",
    "        print('line: ', len(line))\n",
    "        print('headers: ', len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    data = dict(zip(headers, line))\n",
    "    sl_data.append(data)\n",
    "    count += 1\n",
    "\n",
    "gaborone = Site.objects.get(id=40)\n",
    "francistown = Site.objects.get(id=60)\n",
    "already_created = 0\n",
    "count = 0\n",
    "for sl in sl_data:\n",
    "    try:\n",
    "        subject_consent = SubjectConsent.objects.get(subject_identifier=sl.get('subject_identifier'))\n",
    "    except SubjectConsent.DoesNotExist:\n",
    "        print(sl.get('subject-identifier'), '@@@@@@')\n",
    "        raise ValidationError('Missing consent for ', sl.get('subject-identifier'))\n",
    "    else:\n",
    "        sl.update(site=subject_consent.site)\n",
    "    del sl['_state']\n",
    "    sl.update(\n",
    "        created=parser.parse(sl.get('created')).replace(tzinfo=tz),\n",
    "        id=uuid.UUID(sl.get('id'))\n",
    "    )\n",
    "    if sl['modified']:\n",
    "        sl.update(modified=parser.parse(sl.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        sl.update(modified=None)\n",
    "    if sl['report_datetime']:\n",
    "        sl.update(report_datetime=parser.parse(sl.get('report_datetime')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        sl.update(report_datetime=None)\n",
    "    if sl['date_signed']:\n",
    "        sl.update(date_signed=parser.parse(sl.get('date_signed')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        sl.update(date_signed=None)\n",
    "    del sl['tracking_identifier']\n",
    "    del sl['action_identifier']\n",
    "    try:\n",
    "        SubjectLocator.objects.get(subject_identifier=sl.get('subject_identifier'))\n",
    "    except SubjectLocator.DoesNotExist:\n",
    "        subject_locator = SubjectLocator(**sl)\n",
    "        subject_locator.save()\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created subject locator {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total created death report 0\n",
      "Already created 2\n"
     ]
    }
   ],
   "source": [
    "# Import Subject Death\n",
    "from cancer_prn.models import DeathReport, DeathCauseInfo, CauseCategory\n",
    "from cancer_subject.models import SubjectConsent\n",
    "from edc_action_item.models import ActionItem\n",
    "\n",
    "death_cause_info = {\n",
    "    '1': ['No information will ever be available', 'No information will ever be available'],\n",
    "    '3': ['Autopsy', 'Autopsy'],\n",
    "    '4': ['Clinical record', 'Clinical record'],\n",
    "    '5': ['Information from physician/nurse/other health care provider', 'Information from physician/nurse/other health care provider'],\n",
    "    '6': ['Information from participant\\u2019s relatives or friends', 'Information from participant\\u2019s relatives or friends'],\n",
    "    '6': ['Information from participant\\u2019s relatives or friends', 'Information from participant\\u2019s relatives or friends'],\n",
    "    '7': ['Information requested, still pending', 'Information requested, still pending'],\n",
    "    '2': ['Other, specify', 'Other, specify']}\n",
    "\n",
    "cause_category = {\n",
    "    '1': ['No information will ever be available', 'No information will ever be available'],\n",
    "    '8': ['Cancer ', 'Cancer '],\n",
    "    '9': ['HIV infection or HIV/AIDS-related diagnosis', 'HIV infection or HIV/AIDS-related diagnosis'],\n",
    "    '10': ['Disease/injury unrelated to cancer or HIV', 'Disease/injury unrelated to cancer or HIV'],\n",
    "    '11': ['Toxicity from cancer treatment (complications of chemotherapy, radiation, or surgery)', 'Toxicity from cancer treatment (complications of chemotherapy, radiation, or surgery)'],\n",
    "    '12': ['Toxicity from HIV/AIDS treatment (HAART or treatment of HIV/AIDS-related diagnosis)', 'Toxicity from HIV/AIDS treatment (HAART or treatment of HIV/AIDS-related diagnosis)'],\n",
    "    '7': ['Other, specify', 'Other, specify']}\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/crfs/death_report.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "\n",
    "sd_data = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(line)\n",
    "        print('line: ', len(line))\n",
    "        print('headers: ', len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    data = dict(zip(headers, line))\n",
    "    sd_data.append(data)\n",
    "\n",
    "gaborone = Site.objects.get(id=40)\n",
    "francistown = Site.objects.get(id=60)\n",
    "already_created = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "for sd in sd_data:\n",
    "    del sd['tracking_identifier']\n",
    "    del sd['action_identifier']\n",
    "    del sd['_state']\n",
    "    sd.update(\n",
    "        created=parser.parse(sd.get('created')).replace(tzinfo=tz),\n",
    "        id=uuid.UUID(sd.get('id'))\n",
    "    )\n",
    "    if sd['death_date']:\n",
    "        sd.update(death_date=parser.parse(sd.get('death_date')).replace(tzinfo=tz).date())\n",
    "    else:\n",
    "        sd.update(death_date=None)\n",
    "    if sd['modified']:\n",
    "        sd.update(modified=parser.parse(sd.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        sd.update(modified=None)\n",
    "    try:\n",
    "        DeathReport.objects.get(subject_identifier=sd.get('subject_identifier'))\n",
    "    except DeathReport.DoesNotExist:\n",
    "        death_report = DeathReport(**sd)\n",
    "        death_report.save()\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created death report {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total created Subject OffStudy 0\n",
      "Already created 3\n"
     ]
    }
   ],
   "source": [
    "from cancer_prn.models import SubjectOffstudy\n",
    "from cancer_subject.models import SubjectConsent\n",
    "from edc_action_item.models import ActionItem\n",
    "from datetime import timedelta\n",
    "\n",
    "fname = '/Users/coulsonkgathi/source/data_files/live_s_d/crfs/subject_offstudy.csv'\n",
    "f = open(fname, 'r')\n",
    "lines = f.readlines()\n",
    "headers = lines[0]\n",
    "headers = headers.strip()\n",
    "headers = headers.split('|')\n",
    "lines.pop(0)\n",
    "del headers[0]\n",
    "offstudy_data = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.split('|')\n",
    "    del line[0]\n",
    "    if len(line) == len(headers):\n",
    "        data = dict(zip(headers, line))\n",
    "    else:\n",
    "        print(line)\n",
    "        print('line: ', len(line))\n",
    "        print('headers: ', len(headers))\n",
    "        raise ValidationError('Line is not the right size')\n",
    "    data = dict(zip(headers, line))\n",
    "    offstudy_data.append(data)\n",
    "\n",
    "gaborone = Site.objects.get(id=40)\n",
    "francistown = Site.objects.get(id=60)\n",
    "already_created = 0\n",
    "count = 0\n",
    "\n",
    "for off in offstudy_data:\n",
    "    del off['_state']\n",
    "    del off['tracking_identifier']\n",
    "    del off['action_identifier']\n",
    "    if off['modified']:\n",
    "        off.update(modified=parser.parse(off.get('modified')).replace(tzinfo=tz))\n",
    "    else:\n",
    "        off.update(modified=None)\n",
    "    if off['offstudy_date']:\n",
    "        off.update(offschedule_datetime=parser.parse(off.get('offstudy_date')).replace(tzinfo=tz) + timedelta(hours=23))\n",
    "    else:\n",
    "        off.update(offschedule_datetime=None)\n",
    "    if off['offstudy_date']:\n",
    "        off.update(offstudy_date=parser.parse(off.get('offstudy_date')).replace(tzinfo=tz).date())\n",
    "    else:\n",
    "        off.update(offstudy_date=None)\n",
    "    off.update(\n",
    "        created=parser.parse(off.get('created')).replace(tzinfo=tz),\n",
    "        id=uuid.UUID(off.get('id')),\n",
    "    )\n",
    "    try:\n",
    "        of = SubjectOffstudy.objects.get(subject_identifier=off.get('subject_identifier'))\n",
    "    except SubjectOffstudy.DoesNotExist:\n",
    "        subject_offstudy = SubjectOffstudy(**off)\n",
    "        subject_offstudy.save()\n",
    "        count += 1\n",
    "    else:\n",
    "        already_created += 1\n",
    "print(f'Total created Subject OffStudy {count}')\n",
    "print(f'Already created {already_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
